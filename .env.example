# ============================================
# CompliAI Configuration
# ============================================

# Embedding Provider Options:
# - "huggingface" (FREE - runs locally, no API calls!)
# - "gemini" (requires API with limits)
# - "openai" (requires paid API)
EMBEDDING_PROVIDER=huggingface

# LLM Provider Options:
# - "gemini" (free tier with generous limits)
# - "openai" (paid)
# - "ollama" (FREE - runs locally!)
LLM_PROVIDER=gemini

# ============================================
# Google Gemini Configuration (FREE TIER)
# ============================================
# Get your FREE key from: https://makersuite.google.com/app/apikey
# IMPORTANT: Copy the ENTIRE key (starts with AIza), no quotes needed
GOOGLE_API_KEY=AIzaSyD...your_key_here

# Gemini Models (for LLM):
# - "gemini-1.5-flash-latest" (RECOMMENDED - Fast, 1500 req/day, 15 RPM)
# - "gemini-1.5-pro-latest" (Advanced - 50 req/day, 2 RPM)
# - "gemini-pro" (Legacy - being phased out)
GEMINI_MODEL=gemini-1.5-flash-latest

# Gemini Embedding Model (if using EMBEDDING_PROVIDER=gemini)
GEMINI_EMBEDDING_MODEL=models/embedding-001

# ============================================
# OpenAI Configuration (Optional - Paid)
# ============================================
OPENAI_API_KEY=sk-proj-...your_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ============================================
# Ollama Configuration (Optional - FREE Local)
# ============================================
# Install: curl https://ollama.ai/install.sh | sh
# Download model: ollama pull llama2
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# HuggingFace Configuration (FREE Local)
# ============================================
# Model automatically downloaded on first use
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ============================================
# Performance & Optimization
# ============================================
# Enable local caching to reduce API calls
ENABLE_EMBEDDING_CACHE=true

# Disable to save 1 LLM call per query
CHECK_HALLUCINATIONS=false

# Disable Cohere reranking (uses separate API)
USE_RERANKING=false

# ============================================
# Application Configuration
# ============================================
UPLOAD_DIR=./data/uploads
VECTOR_STORE_DIR=./data/vector_store

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Retrieval Configuration
TOP_K_RETRIEVAL=10
RERANK_TOP_N=5
CONFIDENCE_THRESHOLD=0.7

# Logging
LOG_LEVEL=INFO

# ============================================
# LangSmith Configuration (Optional)
# ============================================
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=compliai-assistant
